---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.path = "man/figures/README-"
)
```

<!-- badges: start -->
<!-- badges: end -->

# Overview

**STMoE** (Skew-t Mixture-of-Experts) provides a flexible and robust modelling 
framework for heterogenous data with possibly skewed, heavy-tailed 
distributions and corrupted by atypical observations. **STMoE** consists of a 
mixture of *K* skew-t expert regressors network (of degree *p*) gated by a 
softmax gating network (of degree *q*) and is represented by:

* The gating network parameters `alpha`'s of the softmax net.
* The experts network parameters: The location parameters (regression 
coefficients) `beta`'s, scale parameters `sigma`'s, the skewness parameters 
`lambda`'s and the degree of freedom parameters `nu`'s. **STMoE** thus 
generalises mixtures of (normal, skew-normal, t, and skew-t) distributions and 
mixtures of regressions with these distributions. For example, when $q=0$, we 
retrieve mixtures of (skew-t, t-, skew-normal, or normal) regressions, and when
both $p=0$ and $q=0$, it is a mixture of (skew-t, t-, skew-normal, or normal) 
distributions. It also reduces to the standard (normal, skew-normal, t, and 
skew-t) distribution when we only use a single expert ($K=1$).

Model estimation/learning is performed by a dedicated expectation conditional 
maximization (ECM) algorithm by maximizing the observed data log-likelihood. 
We provide simulated examples to illustrate the use of the model in model-based
clustering of heterogeneous regression data and in fitting non-linear regression
functions.

# Installation

You can install the development version of StMoE from [GitHub](https://github.com/)
with:

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("fchamroukhi/StMoE")
```

To build *vignettes* for examples of usage, type the command below instead:

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("fchamroukhi/StMoE", 
                         build_opts = c("--no-resave-data", "--no-manual"), 
                         build_vignettes = TRUE)
```

Use the following command to display vignettes:

```{r, eval = FALSE}
browseVignettes("StMoE")
```

# Usage

```{r, message = FALSE}
library(StMoE)
```

```{r, echo = TRUE}
# Applicartion to a simulated data set

n <- 500 # Size of the sample
alphak <- matrix(c(0, 8), ncol = 1) # Parameters of the gating network
betak <- matrix(c(0, -2.5, 0, 2.5), ncol = 2) # Regression coefficients of the experts
sigmak <- c(0.5, 0.5) # Standard deviations of the experts
lambdak <- c(3, 5) # Skewness parameters of the experts
nuk <- c(5, 7) # Degrees of freedom of the experts network t densities
x <- seq.int(from = -1, to = 1, length.out = n) # Inputs (predictors)

# Generate sample of size n
sample <- sampleUnivSTMoE(alphak = alphak, betak = betak, sigmak = sigmak, 
                          lambdak = lambdak, nuk = nuk, x = x)
y <- sample$y

K <- 2 # Number of regressors/experts
p <- 1 # Order of the polynomial regression (regressors/experts)
q <- 1 # Order of the logistic regression (gating network)

n_tries <- 1
max_iter <- 1500
threshold <- 1e-5
verbose <- TRUE
verbose_IRLS <- FALSE

stmoe <- emStMoE(X = x, Y = y, K, p, q, n_tries, max_iter, 
                 threshold, verbose, verbose_IRLS)

stmoe$plot()
```

```{r, echo = TRUE}
# Applicartion to a real data set

library(MASS)
data("mcycle")
x <- mcycle$times
y <- mcycle$accel

K <- 4 # Number of regressors/experts
p <- 2 # Order of the polynomial regression (regressors/experts)
q <- 1 # Order of the logistic regression (gating network)

n_tries <- 1
max_iter <- 1500
threshold <- 1e-5
verbose <- TRUE
verbose_IRLS <- FALSE

stmoe <- emStMoE(X = x, Y = y, K, p, q, n_tries, max_iter, 
                 threshold, verbose, verbose_IRLS)

stmoe$plot()
```
